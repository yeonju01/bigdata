## 딥러닝(DNN)
: 인공신경망
1.데이터셋 생성

2.학습과정 설정
x(입력데이터)
y(라벨값)
batch_size(가중치 갱신할 샘플의 갯수) : 정해진 갯수만큼 비교 후 가중치 갱신
epochs(학습 반복 횟수) : 무조건 늘리는 것이 좋은것은 아님
Model.fit() : 히스토리 기능 - loss(손실값), acc(정확도), val_loss(검증 손실값), val_acc(검증 정확도)

3.데이터셋 학습결과 : 검증결과가 오버피팅(과적합)되거나 성급하게 조기종료 되지 않고 적절히 조기종료되는 것이 좋음
EarlyStopping(학습 조기 종료)
(ex)keras.callbacks.EarlyStopping(monitor=‘val_loss’, min_delta=0, patience=0, verbose=0, mode=‘auto’)
monitor : 관찰하는 항목(주로 val_loss, val_acc)
min_delta : 개선되고 있다고 판단하는 최소 변화량
patience : 개선이 없는 에포크를 바로 종료하지 않고 기다리는 횟수
verbose : 정보를 얼마나 자세히 표시할 것인지 지정
mode : 개선을 판단하는 기준(val_loss의 경우 감소하여야하므로 min, auto는 자동지정)

4.평가
성능평가지표(정확도,정밀도,재현율) : 실제 정답과 분류 결과의 비교를 통해 확인

5.학습모델 보기, 저장, 불러오기

## 퍼셉트론
: 입력신호 * 가중치 + 편향 >= 0 -> 1
AND(논리곱) : 모든 입력값이 1인 경우만 1
NAND : 모든 입력값이 1인 경우만 0
OR(논리합) : 하나이상 1인 경우 1
XOR : 입력값이 같지 않은 경우 1
퍼셉트론으로는 못 찾기때문에(선형으로는 무리, 비선형이어야 함) 여러층으로 표현
-> w1, w2, b를 정하고 w1*x1 + w2*x2 + b >=0 일 때 1/ w1*x1 + w2*x2 + b <0 일 때 0 

(ex) AND 퍼셉트론 구현하기
import numpy as np
def AND(x1, x2):
	x = np.array([x1, x2])
	w = np.array([0.5, 0.5])
	b = -0.7
	tmp = np.sum(w*x) + b
	if tmp <= 0:
		return 0
	else:
		return 1
print()
for i in [(0, 0), (1, 0), (0, 1), (1, 1)]:
	y = AND(i[0], i[1])
	print(str(i) + “->” + str(y))
결과 : AND진리표
(0, 0) -> 0
(1, 0) -> 0
(0, 1) -> 0
(1, 1) -> 1

## 다층 퍼셉트론
 : XOR(x1, x2) = AND(NAND(x1, x2), OR(x1, x2)

Dense 레이어 : 입출력을 연결, 가중치가 높을수록 출력 뉴런에 미치는 영향이 큼
(ex) model.add(Dense(8, input_dim=4, init=‘uniform’, activation=‘relu’))
첫번째 인자 : 출력 뉴런의 수
input_dim : 입력 뉴런의 수
init : 가중치 초기화 방법 (uniform:균일분포, normal:가우시안분포)
activation : 활성화 함수 설정(linear:디폴트,입력뉴런과 가중치로 계산된 값 그대로 출력, relu:은닉층에 주로 쓰임, sigmoid:이진분류에서 출력층에 주로 쓰임, softmax:다중분류에서 출력층에 주로 쓰음)
